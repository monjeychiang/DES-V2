# DES Trading System V2.0 - æ€§èƒ½æ”¹é€²è¨ˆç•« V1

> **ç‰ˆæœ¬**: 1.0  
> **å‰µå»ºæ—¥æœŸ**: 2025-12-08  
> **é è¨ˆåŸ·è¡Œé€±æœŸ**: 4-6 é€±  
> **åŸºæ–¼æ–‡æª”**: [æ€§èƒ½åˆ†æå ±å‘Š](../architecture/PERFORMANCE_ANALYSIS.md)

---

## ğŸ“‹ ç›®éŒ„

1. [è¨ˆç•«æ¦‚è¿°](#è¨ˆç•«æ¦‚è¿°)
2. [æ”¹é€²å„ªå…ˆç´šçŸ©é™£](#æ”¹é€²å„ªå…ˆç´šçŸ©é™£)
3. [Phase 1: é—œéµç©©å®šæ€§å„ªåŒ–](#phase-1-é—œéµç©©å®šæ€§å„ªåŒ–)
4. [Phase 2: æ ¸å¿ƒæ€§èƒ½æå‡](#phase-2-æ ¸å¿ƒæ€§èƒ½æå‡)
5. [Phase 3: å¯è§€æ¸¬æ€§å¢å¼·](#phase-3-å¯è§€æ¸¬æ€§å¢å¼·)
6. [Phase 4: æ¶æ§‹é å‚™](#phase-4-æ¶æ§‹é å‚™)
7. [å¯¦æ–½æ™‚é–“è¡¨](#å¯¦æ–½æ™‚é–“è¡¨)
8. [é¢¨éšªè©•ä¼°èˆ‡ç·©è§£](#é¢¨éšªè©•ä¼°èˆ‡ç·©è§£)
9. [é©—æ”¶æ¨™æº–](#é©—æ”¶æ¨™æº–)
10. [å¾ŒçºŒè¦åŠƒ](#å¾ŒçºŒè¦åŠƒ)

---

## è¨ˆç•«æ¦‚è¿°

### 1.1 ç›®æ¨™

åŸºæ–¼æ€§èƒ½åˆ†æå ±å‘Šçš„ç™¼ç¾ï¼Œæœ¬è¨ˆç•«æ—¨åœ¨ï¼š

1. **æå‡ç³»çµ±ç©©å®šæ€§** - è§£æ±º WebSocket æ–·ç·šã€æ¥µç«¯è¡Œæƒ…ç­‰é¢¨éšª
2. **å„ªåŒ–è™•ç†æ•ˆèƒ½** - ç­–ç•¥ä¸¦è¡ŒåŒ–ã€è¨‚å–®è™•ç†å„ªåŒ–
3. **å¢å¼·å¯è§€æ¸¬æ€§** - å®Œå–„ç›£æ§ã€æ—¥èªŒã€è¿½è¹¤æ©Ÿåˆ¶
4. **ç‚ºæ“´å±•åšæº–å‚™** - è³‡æ–™åº«é·ç§»è¦åŠƒã€æ¨¡çµ„åŒ–é‡æ§‹

### 1.2 ç¯„åœ

| åœ¨ç¯„åœå…§ | ä¸åœ¨ç¯„åœå…§ |
|----------|-----------|
| æ ¸å¿ƒå¼•æ“å„ªåŒ– | æ–°äº¤æ˜“æ‰€æ”¯æ´ |
| ç©©å®šæ€§å¢å¼· | UI/UX æ”¹é€² |
| ç›£æ§ç³»çµ± | æ–°ç­–ç•¥é¡å‹ |
| ç¨‹å¼ç¢¼é‡æ§‹ | åˆ†æ•£å¼æ¶æ§‹é·ç§» |

### 1.3 æˆåŠŸæŒ‡æ¨™

| æŒ‡æ¨™ | ç•¶å‰åŸºæº– | ç›®æ¨™å€¼ | æå‡å¹…åº¦ |
|------|----------|--------|----------|
| ç­–ç•¥è™•ç†å»¶é² | ~10ms (10ç­–ç•¥) | <5ms | 50%+ |
| è¨‚å–®ç«¯åˆ°ç«¯å»¶é² | ~50-100ms | <50ms | 50%+ |
| ç³»çµ±å¯ç”¨æ€§ | ~95% | >99% | 4%+ |
| æ¥µç«¯è¡Œæƒ…å­˜æ´»ç‡ | æœªçŸ¥ | >99.9% | - |

---

## æ”¹é€²å„ªå…ˆç´šçŸ©é™£

```
                    é«˜å½±éŸ¿
                      â”‚
         P0-A         â”‚         P0-B
    WebSocket é‡é€£    â”‚    ç­–ç•¥ä¸¦è¡ŒåŒ–
                      â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â”‚
         P1-A         â”‚         P1-B
    è¨‚å–®ä½‡åˆ—å„ªåŒ–      â”‚    ç›£æ§ç³»çµ±
                      â”‚
                    ä½å½±éŸ¿
         ä½ç·Šæ€¥ â—€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â–¶ é«˜ç·Šæ€¥
```

### è©³ç´°å„ªå…ˆç´š

| ID | æ”¹é€²é …ç›® | å„ªå…ˆç´š | å½±éŸ¿ | å·¥ä½œé‡ | é¢¨éšª |
|----|----------|--------|------|--------|------|
| P0-A | WebSocket è‡ªå‹•é‡é€£ | ğŸ”´ P0 | é«˜ | ä¸­ | ä½ |
| P0-B | ç­–ç•¥å¼•æ“ä¸¦è¡ŒåŒ– | ğŸ”´ P0 | é«˜ | ä¸­ | ä¸­ |
| P1-A | è¨‚å–®ä½‡åˆ—å‹•æ…‹æ“´å®¹ | ğŸŸ¡ P1 | ä¸­ | ä½ | ä½ |
| P1-B | æ€§èƒ½ç›£æ§ç³»çµ± | ğŸŸ¡ P1 | ä¸­ | ä¸­ | ä½ |
| P1-C | è³‡æ–™åº«æ‰¹æ¬¡å¯«å…¥ | ğŸŸ¡ P1 | ä¸­ | ä¸­ | ä¸­ |
| P2-A | Price Cache åˆ†ç‰‡ | ğŸŸ¢ P2 | ä½ | ä½ | ä½ |
| P2-B | è¨˜æ†¶é«”æ´©æ¼ä¿®å¾© | ğŸŸ¢ P2 | ä½ | ä½ | ä½ |
| P3-A | è³‡æ–™åº«é·ç§»è©•ä¼° | âšª P3 | è¦åŠƒ | ä½ | ç„¡ |

---

## Phase 1: é—œéµç©©å®šæ€§å„ªåŒ–

**æ™‚é–“**: ç¬¬ 1-2 é€±  
**ç›®æ¨™**: è§£æ±ºç³»çµ±ç©©å®šæ€§éš±æ‚£

### 1.1 P0-A: WebSocket è‡ªå‹•é‡é€£æ©Ÿåˆ¶

#### å•é¡Œæè¿°
ç•¶å‰ WebSocket é€£ç·šæ–·é–‹å¾Œï¼Œç³»çµ±ç„¡æ³•è‡ªå‹•æ¢å¾©ï¼Œå°è‡´ç­–ç•¥å¤±å»è¡Œæƒ…æ•¸æ“šã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `pkg/market/binance/websocket.go`

```go
// æ–°å¢çµæ§‹
type reconnectableConn struct {
    conn       *websocket.Conn
    url        string
    mu         sync.Mutex
    maxRetries int
    backoff    time.Duration
    onReconnect func()
}

// é‡é€£é‚è¼¯
func (r *reconnectableConn) reconnect(ctx context.Context) error {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    for i := 0; i < r.maxRetries; i++ {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
        }
        
        wait := r.backoff * time.Duration(1<<i) // æŒ‡æ•¸é€€é¿
        if wait > 30*time.Second {
            wait = 30 * time.Second
        }
        
        log.Printf("ğŸ”„ WebSocket reconnecting in %v (attempt %d/%d)", 
            wait, i+1, r.maxRetries)
        time.Sleep(wait)
        
        conn, _, err := websocket.DefaultDialer.DialContext(ctx, r.url, nil)
        if err != nil {
            log.Printf("âŒ Reconnect failed: %v", err)
            continue
        }
        
        r.conn = conn
        if r.onReconnect != nil {
            r.onReconnect()
        }
        log.Printf("âœ… WebSocket reconnected successfully")
        return nil
    }
    return fmt.Errorf("max retries exceeded")
}
```

#### ä¿®æ”¹æª”æ¡ˆæ¸…å–®
| æª”æ¡ˆ | è®Šæ›´é¡å‹ | èªªæ˜ |
|------|----------|------|
| `pkg/market/binance/websocket.go` | ä¿®æ”¹ | æ·»åŠ é‡é€£é‚è¼¯ |
| `internal/market/feed.go` | ä¿®æ”¹ | è™•ç†é‡é€£äº‹ä»¶ |
| `pkg/market/binance/types.go` | æ–°å¢ | é‡é€£é…ç½®çµæ§‹ |

#### æ¸¬è©¦è¨ˆç•«
- [ ] å–®å…ƒæ¸¬è©¦ï¼šæ¨¡æ“¬æ–·ç·šé‡é€£
- [ ] æ•´åˆæ¸¬è©¦ï¼šå¯¦éš›æ–·ç¶²æ¢å¾©
- [ ] å£“åŠ›æ¸¬è©¦ï¼šé »ç¹æ–·ç·šå ´æ™¯

#### é©—æ”¶æ¨™æº–
- [ ] æ–·ç·šå¾Œ 30 ç§’å…§è‡ªå‹•é‡é€£
- [ ] é‡é€£å¾Œè‡ªå‹•æ¢å¾©è¨‚é–±
- [ ] é‡é€£å¤±æ•—æœ‰å‘Šè­¦æ©Ÿåˆ¶

---

### 1.2 P0-B: ç­–ç•¥å¼•æ“ä¸¦è¡ŒåŒ–

#### å•é¡Œæè¿°
ç•¶å‰ç­–ç•¥å¼•æ“ä¸²è¡Œè™•ç†æ‰€æœ‰ç­–ç•¥ï¼Œç­–ç•¥æ•¸é‡å¢åŠ æ™‚å»¶é²ç·šæ€§å¢é•·ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/strategy/engine.go`

```go
// æ–°å¢ Worker Pool
type workerPool struct {
    workers int
    tasks   chan func()
    wg      sync.WaitGroup
}

func newWorkerPool(size int) *workerPool {
    wp := &workerPool{
        workers: size,
        tasks:   make(chan func(), size*10),
    }
    for i := 0; i < size; i++ {
        go wp.worker()
    }
    return wp
}

func (wp *workerPool) worker() {
    for task := range wp.tasks {
        task()
        wp.wg.Done()
    }
}

// ä¿®æ”¹ handleTick
func (e *Engine) handleTick(msg any) {
    symbol, price := e.parseMessage(msg)
    if symbol == "" || price <= 0 {
        return
    }
    
    indVals := map[string]float64{}
    if e.ctx.Indicators != nil {
        indVals = e.ctx.Indicators.Update(symbol, price)
    }
    
    // ä¸¦è¡Œè™•ç†ç­–ç•¥
    var wg sync.WaitGroup
    results := make(chan *Signal, len(e.strategies))
    
    for _, s := range e.strategies {
        if e.paused[s.ID()] {
            continue
        }
        
        wg.Add(1)
        strat := s // é¿å…é–‰åŒ…å•é¡Œ
        go func() {
            defer wg.Done()
            sig, err := strat.OnTick(symbol, price, indVals)
            if err != nil {
                log.Printf("strategy %s error: %v", strat.Name(), err)
                return
            }
            if sig != nil {
                sig.StrategyID = strat.ID()
                results <- sig
            }
        }()
    }
    
    // æ”¶é›†çµæœ
    go func() {
        wg.Wait()
        close(results)
    }()
    
    for sig := range results {
        e.bus.Publish(events.EventStrategySignal, *sig)
    }
}
```

#### ä¿®æ”¹æª”æ¡ˆæ¸…å–®
| æª”æ¡ˆ | è®Šæ›´é¡å‹ | èªªæ˜ |
|------|----------|------|
| `internal/strategy/engine.go` | ä¿®æ”¹ | ä¸¦è¡Œè™•ç†é‚è¼¯ |
| `internal/strategy/types.go` | ä¿®æ”¹ | ç¢ºä¿ Strategy ä»‹é¢åŸ·è¡Œç·’å®‰å…¨ |

#### æ¸¬è©¦è¨ˆç•«
- [ ] åŸºæº–æ¸¬è©¦ï¼šä¸²è¡Œ vs ä¸¦è¡Œå°æ¯”
- [ ] ç«¶æ…‹æ¸¬è©¦ï¼š`go test -race`
- [ ] å£“åŠ›æ¸¬è©¦ï¼š50+ ç­–ç•¥ä¸¦è¡Œ

#### é©—æ”¶æ¨™æº–
- [ ] ç„¡ç«¶æ…‹æ¢ä»¶ (race condition)
- [ ] 10 ç­–ç•¥è™•ç†æ™‚é–“ < 2ms
- [ ] CPU åˆ©ç”¨ç‡æå‡ (å¤šæ ¸å¿ƒ)

---

## Phase 2: æ ¸å¿ƒæ€§èƒ½æå‡

**æ™‚é–“**: ç¬¬ 3-4 é€±  
**ç›®æ¨™**: æå‡ç³»çµ±è™•ç†èƒ½åŠ›

### 2.1 P1-A: è¨‚å–®ä½‡åˆ—å‹•æ…‹æ“´å®¹

#### å•é¡Œæè¿°
å›ºå®š 200 æ§½ä½åœ¨æ¥µç«¯è¡Œæƒ…ä¸‹å¯èƒ½ä¸è¶³ï¼Œå°è‡´è¨‚å–®é˜»å¡ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/order/queue.go`

```go
type Queue struct {
    ch          chan Order
    size        int
    mu          sync.RWMutex
    overflowBuf []Order  // æº¢å‡ºç·©è¡
    metrics     *QueueMetrics
}

type QueueMetrics struct {
    Enqueued    uint64
    Dequeued    uint64
    Overflowed  uint64
    MaxPending  int
}

func NewQueue(size int) *Queue {
    if size <= 0 {
        size = 200
    }
    return &Queue{
        ch:          make(chan Order, size),
        size:        size,
        overflowBuf: make([]Order, 0, size/2),
        metrics:     &QueueMetrics{},
    }
}

func (q *Queue) Enqueue(o Order) bool {
    atomic.AddUint64(&q.metrics.Enqueued, 1)
    
    select {
    case q.ch <- o:
        return true
    default:
        // ä¸»é€šé“æ»¿ï¼Œä½¿ç”¨æº¢å‡ºç·©è¡
        q.mu.Lock()
        if len(q.overflowBuf) < cap(q.overflowBuf) {
            q.overflowBuf = append(q.overflowBuf, o)
            atomic.AddUint64(&q.metrics.Overflowed, 1)
            q.mu.Unlock()
            log.Printf("âš ï¸ Order queue overflow, using buffer (%d)", 
                len(q.overflowBuf))
            return true
        }
        q.mu.Unlock()
        log.Printf("âŒ Order queue full, order rejected: %s", o.ID)
        return false
    }
}

func (q *Queue) GetMetrics() QueueMetrics {
    return QueueMetrics{
        Enqueued:   atomic.LoadUint64(&q.metrics.Enqueued),
        Dequeued:   atomic.LoadUint64(&q.metrics.Dequeued),
        Overflowed: atomic.LoadUint64(&q.metrics.Overflowed),
        MaxPending: len(q.ch) + len(q.overflowBuf),
    }
}
```

#### é©—æ”¶æ¨™æº–
- [ ] æ”¯æ´æº¢å‡ºç·©è¡æ©Ÿåˆ¶
- [ ] æä¾›ä½‡åˆ—æŒ‡æ¨™ç›£æ§
- [ ] è¨‚å–®ä¸æœƒéœé»˜ä¸Ÿå¤±

---

### 2.2 P1-C: è³‡æ–™åº«æ‰¹æ¬¡å¯«å…¥

#### å•é¡Œæè¿°
æ¯ç­†äº¤æ˜“ç¨ç«‹å¯«å…¥ DBï¼Œé«˜é »å ´æ™¯ä¸‹ I/O æˆç‚ºç“¶é ¸ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æ–°æª”æ¡ˆ**: `internal/persistence/batch_writer.go`

```go
package persistence

import (
    "context"
    "database/sql"
    "log"
    "sync"
    "time"
)

type BatchWriter struct {
    db          *sql.DB
    buffer      []WriteOp
    mu          sync.Mutex
    maxSize     int
    flushIntval time.Duration
    done        chan struct{}
}

type WriteOp struct {
    Table  string
    Query  string
    Args   []any
}

func NewBatchWriter(db *sql.DB, maxSize int, interval time.Duration) *BatchWriter {
    bw := &BatchWriter{
        db:          db,
        buffer:      make([]WriteOp, 0, maxSize),
        maxSize:     maxSize,
        flushIntval: interval,
        done:        make(chan struct{}),
    }
    go bw.backgroundFlush()
    return bw
}

func (bw *BatchWriter) Write(op WriteOp) {
    bw.mu.Lock()
    bw.buffer = append(bw.buffer, op)
    shouldFlush := len(bw.buffer) >= bw.maxSize
    bw.mu.Unlock()
    
    if shouldFlush {
        bw.Flush()
    }
}

func (bw *BatchWriter) Flush() error {
    bw.mu.Lock()
    if len(bw.buffer) == 0 {
        bw.mu.Unlock()
        return nil
    }
    ops := bw.buffer
    bw.buffer = make([]WriteOp, 0, bw.maxSize)
    bw.mu.Unlock()
    
    tx, err := bw.db.Begin()
    if err != nil {
        return err
    }
    
    for _, op := range ops {
        if _, err := tx.Exec(op.Query, op.Args...); err != nil {
            tx.Rollback()
            log.Printf("âŒ Batch write failed: %v", err)
            return err
        }
    }
    
    if err := tx.Commit(); err != nil {
        return err
    }
    
    log.Printf("ğŸ’¾ Batch write: %d operations", len(ops))
    return nil
}

func (bw *BatchWriter) backgroundFlush() {
    ticker := time.NewTicker(bw.flushIntval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            bw.Flush()
        case <-bw.done:
            bw.Flush() // æœ€å¾Œä¸€æ¬¡åˆ·æ–°
            return
        }
    }
}

func (bw *BatchWriter) Close() {
    close(bw.done)
}
```

#### ä½¿ç”¨æ–¹å¼
```go
// main.go
batchWriter := persistence.NewBatchWriter(database.DB, 50, 500*time.Millisecond)
defer batchWriter.Close()

// æ›¿æ›ç›´æ¥å¯«å…¥
batchWriter.Write(persistence.WriteOp{
    Table: "trades",
    Query: "INSERT INTO trades (...) VALUES (?, ?, ?)",
    Args:  []any{trade.ID, trade.Symbol, trade.Price},
})
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰¹æ¬¡å¤§å°å¯é…ç½®
- [ ] å®šæ™‚åˆ·æ–°æ©Ÿåˆ¶
- [ ] é—œé–‰æ™‚ç¢ºä¿æ•¸æ“šå®Œæ•´

---

## Phase 3: å¯è§€æ¸¬æ€§å¢å¼·

**æ™‚é–“**: ç¬¬ 5 é€±  
**ç›®æ¨™**: å®Œå–„ç›£æ§ã€æ—¥èªŒã€è¿½è¹¤

### 3.1 P1-B: æ€§èƒ½ç›£æ§ç³»çµ±

#### å¯¦æ–½æ–¹æ¡ˆ

**æ–°æª”æ¡ˆ**: `internal/monitor/metrics.go`

```go
package monitor

import (
    "sync"
    "time"
)

type SystemMetrics struct {
    mu sync.RWMutex
    
    // å»¶é²æŒ‡æ¨™
    OrderLatency    *LatencyHistogram
    StrategyLatency *LatencyHistogram
    DBLatency       *LatencyHistogram
    
    // ååæŒ‡æ¨™
    OrdersPerSecond   float64
    TicksPerSecond    float64
    SignalsPerSecond  float64
    
    // è³‡æºæŒ‡æ¨™
    GoroutineCount    int
    HeapAlloc         uint64
    QueueDepth        int
    
    // éŒ¯èª¤è¨ˆæ•¸
    ErrorCount        map[string]uint64
    
    // æ™‚é–“æˆ³
    LastUpdate        time.Time
}

type LatencyHistogram struct {
    mu      sync.Mutex
    samples []float64
    maxSize int
}

func NewLatencyHistogram(size int) *LatencyHistogram {
    return &LatencyHistogram{
        samples: make([]float64, 0, size),
        maxSize: size,
    }
}

func (h *LatencyHistogram) Record(latencyMs float64) {
    h.mu.Lock()
    defer h.mu.Unlock()
    
    if len(h.samples) >= h.maxSize {
        h.samples = h.samples[1:]  // æ»‘å‹•çª—å£
    }
    h.samples = append(h.samples, latencyMs)
}

func (h *LatencyHistogram) Percentile(p float64) float64 {
    h.mu.Lock()
    defer h.mu.Unlock()
    
    if len(h.samples) == 0 {
        return 0
    }
    
    // ç°¡åŒ–ç‰ˆç™¾åˆ†ä½è¨ˆç®—
    sorted := make([]float64, len(h.samples))
    copy(sorted, h.samples)
    sort.Float64s(sorted)
    
    idx := int(float64(len(sorted)-1) * p)
    return sorted[idx]
}

func (h *LatencyHistogram) Stats() (min, max, avg, p50, p99 float64) {
    h.mu.Lock()
    defer h.mu.Unlock()
    
    if len(h.samples) == 0 {
        return
    }
    
    min, max = h.samples[0], h.samples[0]
    sum := 0.0
    for _, v := range h.samples {
        if v < min { min = v }
        if v > max { max = v }
        sum += v
    }
    avg = sum / float64(len(h.samples))
    
    sorted := make([]float64, len(h.samples))
    copy(sorted, h.samples)
    sort.Float64s(sorted)
    
    p50 = sorted[len(sorted)/2]
    p99 = sorted[int(float64(len(sorted)-1)*0.99)]
    return
}
```

#### API ç«¯é»

**æ–°å¢è·¯ç”±** (`internal/api/handler.go`):

```go
// GET /api/metrics
func (s *Server) getMetrics(c *gin.Context) {
    metrics := s.monitor.GetMetrics()
    c.JSON(http.StatusOK, metrics)
}

// GET /api/metrics/latency
func (s *Server) getLatencyMetrics(c *gin.Context) {
    orderMin, orderMax, orderAvg, orderP50, orderP99 := 
        s.monitor.OrderLatency.Stats()
    
    c.JSON(http.StatusOK, gin.H{
        "order": gin.H{
            "min": orderMin, "max": orderMax, "avg": orderAvg,
            "p50": orderP50, "p99": orderP99,
        },
        "strategy": s.monitor.StrategyLatency.Stats(),
        "database": s.monitor.DBLatency.Stats(),
    })
}
```

#### é©—æ”¶æ¨™æº–
- [ ] æä¾› `/api/metrics` ç«¯é»
- [ ] å»¶é²ç™¾åˆ†ä½çµ±è¨ˆ (P50, P99)
- [ ] Goroutine èˆ‡è¨˜æ†¶é«”ç›£æ§

---

### 3.2 çµæ§‹åŒ–æ—¥èªŒå¢å¼·

#### å¯¦æ–½æ–¹æ¡ˆ

**æ–°æª”æ¡ˆ**: `pkg/logger/logger.go`

```go
package logger

import (
    "encoding/json"
    "log"
    "os"
    "time"
)

type Logger struct {
    output *log.Logger
    level  Level
}

type Level int

const (
    DEBUG Level = iota
    INFO
    WARN
    ERROR
)

type LogEntry struct {
    Timestamp string         `json:"ts"`
    Level     string         `json:"level"`
    Message   string         `json:"msg"`
    Module    string         `json:"module,omitempty"`
    Fields    map[string]any `json:"fields,omitempty"`
}

func New(level Level) *Logger {
    return &Logger{
        output: log.New(os.Stdout, "", 0),
        level:  level,
    }
}

func (l *Logger) log(level Level, module, msg string, fields map[string]any) {
    if level < l.level {
        return
    }
    
    entry := LogEntry{
        Timestamp: time.Now().Format(time.RFC3339Nano),
        Level:     levelName(level),
        Message:   msg,
        Module:    module,
        Fields:    fields,
    }
    
    data, _ := json.Marshal(entry)
    l.output.Println(string(data))
}

func (l *Logger) Info(module, msg string, fields map[string]any) {
    l.log(INFO, module, msg, fields)
}

func (l *Logger) Error(module, msg string, fields map[string]any) {
    l.log(ERROR, module, msg, fields)
}

func levelName(l Level) string {
    switch l {
    case DEBUG: return "DEBUG"
    case INFO:  return "INFO"
    case WARN:  return "WARN"
    case ERROR: return "ERROR"
    default:    return "UNKNOWN"
    }
}
```

---

## Phase 4: æ¶æ§‹é å‚™

**æ™‚é–“**: ç¬¬ 6 é€±  
**ç›®æ¨™**: ç‚ºæœªä¾†æ“´å±•åšæº–å‚™

### 4.1 P2-A: Price Cache åˆ†ç‰‡

**æª”æ¡ˆ**: `pkg/cache/sharded_cache.go`

```go
package cache

import (
    "hash/fnv"
    "sync"
)

const numShards = 16

type ShardedPriceCache struct {
    shards [numShards]*priceShard
}

type priceShard struct {
    mu    sync.RWMutex
    items map[string]float64
}

func NewShardedPriceCache() *ShardedPriceCache {
    c := &ShardedPriceCache{}
    for i := 0; i < numShards; i++ {
        c.shards[i] = &priceShard{
            items: make(map[string]float64),
        }
    }
    return c
}

func (c *ShardedPriceCache) getShard(key string) *priceShard {
    h := fnv.New32a()
    h.Write([]byte(key))
    return c.shards[h.Sum32()%numShards]
}

func (c *ShardedPriceCache) Set(symbol string, price float64) {
    shard := c.getShard(symbol)
    shard.mu.Lock()
    shard.items[symbol] = price
    shard.mu.Unlock()
}

func (c *ShardedPriceCache) Get(symbol string) (float64, bool) {
    shard := c.getShard(symbol)
    shard.mu.RLock()
    price, ok := shard.items[symbol]
    shard.mu.RUnlock()
    return price, ok
}
```

---

### 4.2 P2-B: è¨˜æ†¶é«”æ´©æ¼ä¿®å¾©

#### ä¿®å¾©é …ç›®

1. **Price Cache æ¸…ç†æ©Ÿåˆ¶**
```go
// å®šæœŸæ¸…ç†éæœŸæˆ–ç„¡æ•ˆçš„åƒ¹æ ¼
func (c *ShardedPriceCache) Cleanup(validSymbols []string) {
    valid := make(map[string]bool)
    for _, s := range validSymbols {
        valid[s] = true
    }
    
    for _, shard := range c.shards {
        shard.mu.Lock()
        for sym := range shard.items {
            if !valid[sym] {
                delete(shard.items, sym)
            }
        }
        shard.mu.Unlock()
    }
}
```

2. **Gateway Cache TTL**
```go
type gatewayEntry struct {
    gateway   exchange.Gateway
    createdAt time.Time
}

// å®šæœŸæ¸…ç†é–’ç½®é€£ç·š
func (e *Executor) cleanupIdleGateways(maxAge time.Duration) {
    e.mu.Lock()
    defer e.mu.Unlock()
    
    now := time.Now()
    for id, entry := range e.connGateways {
        if now.Sub(entry.createdAt) > maxAge {
            delete(e.connGateways, id)
            log.Printf("ğŸ—‘ï¸ Cleaned up idle gateway: %s", id)
        }
    }
}
```

---

### 4.3 P3-A: è³‡æ–™åº«é·ç§»è©•ä¼°

#### è©•ä¼°çŸ©é™£

| é¸é … | å„ªé» | ç¼ºé» | é©ç”¨å ´æ™¯ |
|------|------|------|----------|
| **SQLite + Redis** | æ”¹å‹•å°ã€å¿«å–æ•ˆæœå¥½ | å…©å¥—ç³»çµ±ç¶­è­· | ä¸­é »äº¤æ˜“ |
| **PostgreSQL** | åŠŸèƒ½å¼·å¤§ã€æ“´å±•æ€§å¥½ | éœ€é·ç§»ã€é‹ç¶­è¤‡é›œ | é«˜é »äº¤æ˜“ |
| **ClickHouse** | æ™‚åºå„ªåŒ–ã€åˆ†æå¼· | å­¸ç¿’æ›²ç·šé«˜ | æ•¸æ“šåˆ†æ |

#### é·ç§»è·¯ç·šåœ– (æœªä¾†)

```
Phase A (ç¾åœ¨): SQLite å„ªåŒ–
    â†“
Phase B (V2.1): SQLite + Redis å¿«å–å±¤
    â†“
Phase C (V3.0): PostgreSQL å…¨é¢é·ç§»
```

---

## å¯¦æ–½æ™‚é–“è¡¨

```
Week 1         Week 2         Week 3         Week 4         Week 5         Week 6
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 1    â”‚   Phase 1    â”‚   Phase 2    â”‚   Phase 2    â”‚   Phase 3    â”‚   Phase 4    â”‚
â”‚              â”‚              â”‚              â”‚              â”‚              â”‚              â”‚
â”‚ P0-A: WSé‡é€£ â”‚ P0-B: ä¸¦è¡ŒåŒ– â”‚ P1-A: ä½‡åˆ—   â”‚ P1-C: æ‰¹æ¬¡DB â”‚ P1-B: ç›£æ§   â”‚ P2: å„ªåŒ–     â”‚
â”‚              â”‚              â”‚              â”‚              â”‚              â”‚              â”‚
â”‚ â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘   â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘   â”‚ â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘   â”‚ â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘   â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘   â”‚ â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é‡Œç¨‹ç¢‘:
M1 (Week 2): Phase 1 å®Œæˆ - ç©©å®šæ€§é”æ¨™
M2 (Week 4): Phase 2 å®Œæˆ - æ€§èƒ½é”æ¨™  
M3 (Week 5): Phase 3 å®Œæˆ - ç›£æ§ä¸Šç·š
M4 (Week 6): Phase 4 å®Œæˆ - å„ªåŒ–æ”¶å°¾
```

### è©³ç´°ä»»å‹™åˆ†è§£

| é€±æ¬¡ | ä»»å‹™ | è² è²¬ | äº¤ä»˜ç‰© |
|------|------|------|--------|
| W1 | WebSocket é‡é€£å¯¦ä½œ | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ + å–®å…ƒæ¸¬è©¦ |
| W1 | é‡é€£é‚è¼¯æ•´åˆæ¸¬è©¦ | QA | æ¸¬è©¦å ±å‘Š |
| W2 | ç­–ç•¥ä¸¦è¡ŒåŒ–å¯¦ä½œ | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ + åŸºæº–æ¸¬è©¦ |
| W2 | Race condition æ¸¬è©¦ | QA | æ¸¬è©¦å ±å‘Š |
| W3 | è¨‚å–®ä½‡åˆ—å„ªåŒ– | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ |
| W3 | å£“åŠ›æ¸¬è©¦ | QA | æ€§èƒ½å ±å‘Š |
| W4 | æ‰¹æ¬¡å¯«å…¥å¯¦ä½œ | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ |
| W4 | æ•´åˆæ¸¬è©¦ | QA | æ¸¬è©¦å ±å‘Š |
| W5 | ç›£æ§ç³»çµ±å¯¦ä½œ | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ + API |
| W5 | ç›£æ§å„€è¡¨æ¿ | å‰ç«¯åœ˜éšŠ | UI çµ„ä»¶ |
| W6 | Cache åˆ†ç‰‡ + æ¸…ç† | æ ¸å¿ƒåœ˜éšŠ | ç¨‹å¼ç¢¼ |
| W6 | æ–‡æª”æ›´æ–° | å…¨é«” | æ›´æ–°æ–‡æª” |

---

## é¢¨éšªè©•ä¼°èˆ‡ç·©è§£

| é¢¨éšª | å¯èƒ½æ€§ | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|--------|------|----------|
| ä¸¦è¡ŒåŒ–å¼•å…¥ç«¶æ…‹æ¢ä»¶ | ä¸­ | é«˜ | ä½¿ç”¨ `-race` æ¸¬è©¦ã€code review |
| æ‰¹æ¬¡å¯«å…¥è³‡æ–™éºå¤± | ä½ | é«˜ | ç¢ºä¿ graceful shutdown |
| é‡é€£æ©Ÿåˆ¶ç„¡é™å¾ªç’° | ä½ | ä¸­ | è¨­ç½®æœ€å¤§é‡è©¦æ¬¡æ•¸å’Œç†”æ–· |
| ç›£æ§ç³»çµ±å¢åŠ é–‹éŠ· | ä¸­ | ä½ | ä½¿ç”¨ä½é–‹éŠ·çš„æŒ‡æ¨™æ”¶é›† |
| æ™‚ç¨‹å»¶èª¤ | ä¸­ | ä¸­ | é ç•™ bufferã€å„ªå…ˆç´šèª¿æ•´ |

---

## é©—æ”¶æ¨™æº–

### Phase 1 é©—æ”¶
- [ ] WebSocket æ–·ç·šå¾Œ 30 ç§’å…§è‡ªå‹•é‡é€£æˆåŠŸç‡ > 99%
- [ ] 10 å€‹ç­–ç•¥ä¸¦è¡Œè™•ç†å»¶é² < 2ms
- [ ] ç„¡ç«¶æ…‹æ¢ä»¶ (`go test -race` é€šé)

### Phase 2 é©—æ”¶
- [ ] è¨‚å–®ä½‡åˆ—æ”¯æ´æº¢å‡ºç·©è¡ï¼Œç„¡éœé»˜ä¸Ÿå¤±
- [ ] æ‰¹æ¬¡å¯«å…¥ååé‡æå‡ 3x ä»¥ä¸Š
- [ ] DB å»¶é² P99 < 50ms

### Phase 3 é©—æ”¶
- [ ] `/api/metrics` ç«¯é»å›æ‡‰æ­£å¸¸
- [ ] æä¾› P50/P99 å»¶é²çµ±è¨ˆ
- [ ] çµæ§‹åŒ–æ—¥èªŒæ ¼å¼æ­£ç¢º

### Phase 4 é©—æ”¶
- [ ] Price Cache åˆ†ç‰‡å¾Œé–ç«¶çˆ­é™ä½
- [ ] è¨˜æ†¶é«”æ´©æ¼ä¿®å¾©é©—è­‰

---

## å¾ŒçºŒè¦åŠƒ

### V2.1 è¦åŠƒ (æœ¬è¨ˆç•«ä¹‹å¾Œ)

1. **Redis å¿«å–å±¤**
   - ç†±é»æ•¸æ“šå¿«å–
   - Session ç®¡ç†

2. **å¥åº·æª¢æŸ¥å¢å¼·**
   - Exchange é€£ç·šå¥åº·
   - ç­–ç•¥åŸ·è¡Œå¥åº·

3. **å‘Šè­¦ç³»çµ±**
   - Telegram æ•´åˆ
   - Discord æ•´åˆ

### V3.0 é æœŸè¦åŠƒ

1. **å¾®æœå‹™æ‹†åˆ†**
2. **PostgreSQL é·ç§»**
3. **Kubernetes éƒ¨ç½²**

---

## é™„éŒ„

### A. ç›¸é—œæ–‡ä»¶

- [æ€§èƒ½åˆ†æå ±å‘Š](../architecture/PERFORMANCE_ANALYSIS.md)
- [ç³»çµ±æ¶æ§‹](../architecture/SYSTEM_ARCHITECTURE.md)
- [é–‹ç™¼è·¯ç·šåœ–](DEVELOPMENT_ROADMAP_DES_V2.md)

### B. è®Šæ›´è¨˜éŒ„

| ç‰ˆæœ¬ | æ—¥æœŸ | è®Šæ›´å…§å®¹ |
|------|------|----------|
| V1.0 | 2025-12-08 | åˆç‰ˆæ”¹é€²è¨ˆç•« |

---

*æœ¬è¨ˆç•«å°‡æ ¹æ“šå¯¦æ–½éç¨‹ä¸­çš„åé¥‹é€²è¡Œèª¿æ•´ã€‚ä»»ä½•é‡å¤§è®Šæ›´éœ€ç¶“åœ˜éšŠè¨è«–ç¢ºèªã€‚*
