# DES Trading System V2.0 - æ€§èƒ½æ”¹é€²è¨ˆç•« V2

> **ç‰ˆæœ¬**: 2.0  
> **å‰µå»ºæ—¥æœŸ**: 2025-12-08  
> **é è¨ˆåŸ·è¡Œé€±æœŸ**: 4-6 é€±  
> **å‰ç½®æ¢ä»¶**: V1 æ”¹é€²è¨ˆç•«å·²å®Œæˆ  
> **åŸºæ–¼æ–‡æª”**: [æ€§èƒ½åˆ†æå ±å‘Š V2](../architecture/PERFORMANCE_ANALYSIS.md)

---

## ğŸ“‹ ç›®éŒ„

1. [è¨ˆç•«æ¦‚è¿°](#è¨ˆç•«æ¦‚è¿°)
2. [V1 æ”¹é€²å›é¡§](#v1-æ”¹é€²å›é¡§)
3. [V2 æ”¹é€²å„ªå…ˆç´šçŸ©é™£](#v2-æ”¹é€²å„ªå…ˆç´šçŸ©é™£)
4. [Phase 1: é—œéµç©©å®šæ€§å¼·åŒ–](#phase-1-é—œéµç©©å®šæ€§å¼·åŒ–)
5. [Phase 2: æ€§èƒ½æ·±åº¦å„ªåŒ–](#phase-2-æ€§èƒ½æ·±åº¦å„ªåŒ–)
6. [Phase 3: æ¶æ§‹å‡ç´šæº–å‚™](#phase-3-æ¶æ§‹å‡ç´šæº–å‚™)
7. [Phase 4: è³‡æ–™åº«é·ç§»](#phase-4-è³‡æ–™åº«é·ç§»)
8. [å¯¦æ–½æ™‚é–“è¡¨](#å¯¦æ–½æ™‚é–“è¡¨)
9. [é¢¨éšªè©•ä¼°èˆ‡ç·©è§£](#é¢¨éšªè©•ä¼°èˆ‡ç·©è§£)
10. [é©—æ”¶æ¨™æº–](#é©—æ”¶æ¨™æº–)

---

## è¨ˆç•«æ¦‚è¿°

### 1.1 èƒŒæ™¯

V1 æ”¹é€²è¨ˆç•«å·²æˆåŠŸå®Œæˆï¼Œç³»çµ±èƒ½åŠ›å¤§å¹…æå‡ï¼š

| æ”¹é€²é …ç›® | æ•ˆæœ |
|----------|------|
| ç­–ç•¥ä¸¦è¡ŒåŒ– | æ“´å±•æ€§ 5-10x |
| WebSocket é‡é€£ | ç©©å®šæ€§ +++ |
| è¨‚å–®ä½‡åˆ—æº¢å‡ºç·©è¡ | å®¹éŒ¯æ€§ +++ |
| åˆ†ç‰‡å¿«å– | ä¸¦ç™¼ 16x |
| æ‰¹æ¬¡å¯«å…¥å™¨ | åå 3-5x (å¯é¸) |
| æ€§èƒ½ç›£æ§ | å¯è§€æ¸¬æ€§ +++ |

### 1.2 V2 ç›®æ¨™

åŸºæ–¼ V2 æ€§èƒ½åˆ†æå ±å‘Šè­˜åˆ¥çš„æ–°ç“¶é ¸ï¼Œæœ¬è¨ˆç•«æ—¨åœ¨ï¼š

1. **æ¶ˆé™¤ Goroutine é¢¨éšª** - Worker Pool é™åˆ¶ä¸¦ç™¼
2. **æå‡è¨‚å–®åŸ·è¡Œæ•ˆç‡** - ç•°æ­¥åŸ·è¡Œ + ä¸¦è¡Œè™•ç†
3. **å„ªåŒ–ç›£æ§ç³»çµ±** - æƒ°æ€§è¨ˆç®—æ¸›å°‘é–‹éŠ·
4. **çªç ´ SQLite é™åˆ¶** - PostgreSQL é·ç§»

### 1.3 ç¯„åœ

| åœ¨ç¯„åœå…§ | ä¸åœ¨ç¯„åœå…§ |
|----------|-----------|
| ç­–ç•¥åŸ·è¡Œå„ªåŒ– | æ–°ç­–ç•¥é¡å‹é–‹ç™¼ |
| è¨‚å–®è™•ç†æ”¹é€² | æ–°äº¤æ˜“æ‰€æ”¯æ´ |
| è³‡æ–™åº«é·ç§» | å¾®æœå‹™æ‹†åˆ† |
| ç›£æ§ç³»çµ±å„ªåŒ– | UI/UX æ”¹é€² |

### 1.4 æˆåŠŸæŒ‡æ¨™

| æŒ‡æ¨™ | V1 å¾ŒåŸºæº– | V2 ç›®æ¨™ | æå‡å¹…åº¦ |
|------|-----------|---------|----------|
| ç­–ç•¥è™•ç†å»¶é² (20 ç­–ç•¥) | ~5ms | <2ms | 60%+ |
| è¨‚å–®ç«¯åˆ°ç«¯å»¶é² P99 | ~100ms | <50ms | 50%+ |
| æœ€å¤§ç­–ç•¥æ•¸é‡ | ~50 | **ç„¡é™** (worker pool) | âˆ |
| è¨‚å–® TPS | ~20 | >100 | 5x |
| /api/metrics å»¶é² | ~10ms | <1ms | 10x |

---

## V1 æ”¹é€²å›é¡§

### 2.1 å·²å®Œæˆé …ç›®

| ID | é …ç›® | ç‹€æ…‹ | æª”æ¡ˆ |
|----|------|------|------|
| P0-A | WebSocket è‡ªå‹•é‡é€£ | âœ… | `pkg/market/binance/websocket.go` |
| P0-B | ç­–ç•¥å¼•æ“ä¸¦è¡ŒåŒ– | âœ… | `internal/strategy/engine.go` |
| P1-A | è¨‚å–®ä½‡åˆ—æº¢å‡ºç·©è¡ | âœ… | `internal/order/queue.go` |
| P1-B | æ€§èƒ½ç›£æ§ç³»çµ± | âœ… | `internal/monitor/metrics.go` |
| P1-C | æ‰¹æ¬¡å¯«å…¥å™¨ | âœ… | `internal/persistence/batch_writer.go` |
| P2-A | åˆ†ç‰‡å¿«å– | âœ… | `pkg/cache/sharded_cache.go` |
| P2-B | å¿«å–æ¸…ç†æ©Ÿåˆ¶ | âœ… | `pkg/cache/sharded_cache.go` |

### 2.2 V2 æ–°è­˜åˆ¥å•é¡Œ

| å•é¡Œ | ä¾†æº | åš´é‡åº¦ |
|------|------|--------|
| ç­–ç•¥ç„¡ Worker Pool é™åˆ¶ | V2 åˆ†æ | ğŸ”´ é«˜ |
| è¨‚å–®åŒæ­¥åŸ·è¡Œé˜»å¡ | V2 åˆ†æ | ğŸ”´ é«˜ |
| Drain é–é »ç¹ | V2 åˆ†æ | ğŸŸ¡ ä¸­ |
| Stats() O(n log n) é–‹éŠ· | V2 åˆ†æ | ğŸŸ¡ ä¸­ |
| BatchWriter æŒ‡æ¨™æœªè¿½è¹¤ | V2 åˆ†æ | ğŸŸ¢ ä½ |
| ç­–ç•¥ç„¡ Panic Recovery | V2 åˆ†æ | ğŸŸ¡ ä¸­ |
| SQLite ä»å–®é€£ç·š | V1 éºç•™ | ğŸ”´ é«˜ |

---

## V2 æ”¹é€²å„ªå…ˆç´šçŸ©é™£

```
                    é«˜å½±éŸ¿
                      â”‚
         P0-A         â”‚         P0-B
    Worker Pool       â”‚    è¨‚å–®ç•°æ­¥åŸ·è¡Œ
                      â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â”‚
         P1-A         â”‚         P1-B
    Panic Recovery    â”‚    æƒ°æ€§ Stats
                      â”‚
                    ä½å½±éŸ¿
         ä½ç·Šæ€¥ â—€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â–¶ é«˜ç·Šæ€¥
```

### è©³ç´°å„ªå…ˆç´š

| ID | æ”¹é€²é …ç›® | å„ªå…ˆç´š | å½±éŸ¿ | å·¥ä½œé‡ | é¢¨éšª |
|----|----------|--------|------|--------|------|
| P0-A | ç­–ç•¥ Worker Pool | ğŸ”´ P0 | é«˜ | ä½ | ä½ |
| P0-B | è¨‚å–®ç•°æ­¥åŸ·è¡Œ | ğŸ”´ P0 | é«˜ | ä¸­ | ä¸­ |
| P1-A | Panic Recovery | ğŸŸ¡ P1 | ä¸­ | ä½ | ä½ |
| P1-B | æƒ°æ€§ Stats è¨ˆç®— | ğŸŸ¡ P1 | ä¸­ | ä½ | ä½ |
| P1-C | æ‰¹é‡ Drain Overflow | ğŸŸ¡ P1 | ä¸­ | ä½ | ä½ |
| P1-D | BatchWriter æŒ‡æ¨™è¿½è¹¤ | ğŸŸ¡ P1 | ä½ | ä½ | ä½ |
| P2-A | PostgreSQL é·ç§»è©•ä¼° | ğŸŸ¢ P2 | è¦åŠƒ | ä¸­ | ç„¡ |
| P2-B | Redis å¿«å–å±¤ | ğŸŸ¢ P2 | è¦åŠƒ | é«˜ | ä¸­ |

---

## Phase 1: é—œéµç©©å®šæ€§å¼·åŒ–

**æ™‚é–“**: ç¬¬ 1-2 é€±  
**ç›®æ¨™**: æ¶ˆé™¤ Goroutine çˆ†ç™¼é¢¨éšªï¼Œç¢ºä¿ç³»çµ±ç©©å®š

### 1.1 P0-A: ç­–ç•¥ Worker Pool

#### å•é¡Œæè¿°
ç•¶å‰ç­–ç•¥ä¸¦è¡ŒåŒ–ç‚ºæ¯å€‹ tick å‰µå»º N å€‹ goroutine (N=ç­–ç•¥æ•¸)ï¼Œé«˜é »å ´æ™¯å¯èƒ½å°è‡´ goroutine æ´©æ¼ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/strategy/engine.go`

```go
// ä¿®æ”¹ Engine çµæ§‹é«”
type Engine struct {
    strategies  []Strategy
    paused      map[string]bool
    bus         *events.Bus
    ctx         Context
    db          *sql.DB
    dataService *data.HistoricalDataService
    
    // æ–°å¢
    workerPool  chan struct{}
    poolSize    int
}

// ä¿®æ”¹ NewEngine
func NewEngine(bus *events.Bus, db *sql.DB, ctx Context) *Engine {
    poolSize := runtime.NumCPU() * 2
    if poolSize < 4 {
        poolSize = 4
    }
    
    return &Engine{
        strategies:  make([]Strategy, 0),
        paused:      make(map[string]bool),
        bus:         bus,
        ctx:         ctx,
        db:          db,
        workerPool:  make(chan struct{}, poolSize),
        poolSize:    poolSize,
    }
}

// ä¿®æ”¹ handleTick
func (e *Engine) handleTick(msg any) {
    // ... è§£æ symbol, price ...
    
    activeStrategies := e.getActiveStrategies()
    if len(activeStrategies) == 0 {
        return
    }
    
    var wg sync.WaitGroup
    signals := make(chan *Signal, len(activeStrategies))
    
    for _, s := range activeStrategies {
        wg.Add(1)
        
        // ç²å– worker slot (é™åˆ¶ä¸¦ç™¼)
        e.workerPool <- struct{}{}
        
        go func(strat Strategy) {
            defer wg.Done()
            defer func() { <-e.workerPool }()  // é‡‹æ”¾ worker slot
            defer e.recoverFromPanic(strat.ID())
            
            sig, err := strat.OnTick(symbol, price, indVals)
            if err != nil {
                log.Printf("strategy %s error: %v", strat.Name(), err)
                return
            }
            if sig != nil {
                sig.StrategyID = strat.ID()
                signals <- sig
            }
        }(s)
    }
    
    go func() {
        wg.Wait()
        close(signals)
    }()
    
    for sig := range signals {
        e.bus.Publish(events.EventStrategySignal, *sig)
    }
}
```

#### ä¿®æ”¹æª”æ¡ˆæ¸…å–®
| æª”æ¡ˆ | è®Šæ›´é¡å‹ | èªªæ˜ |
|------|----------|------|
| `internal/strategy/engine.go` | ä¿®æ”¹ | æ–°å¢ workerPool, poolSize æ¬„ä½ |

#### æ¸¬è©¦è¨ˆç•«
- [ ] å–®å…ƒæ¸¬è©¦ï¼šé™åˆ¶ä¸¦ç™¼æ•¸é©—è­‰
- [ ] å£“åŠ›æ¸¬è©¦ï¼š100+ ç­–ç•¥ + é«˜é » tick
- [ ] ç›£æ§æ¸¬è©¦ï¼š`/api/metrics` Goroutine æ•¸é‡ç©©å®š

#### é©—æ”¶æ¨™æº–
- [ ] Goroutine æ•¸é‡ä¸è¶…é poolSize Ã— 2
- [ ] é«˜é »å ´æ™¯ä¸‹ç„¡ goroutine æ´©æ¼
- [ ] æ•ˆèƒ½ç„¡æ˜é¡¯ä¸‹é™

---

### 1.2 P1-A: Panic Recovery

#### å•é¡Œæè¿°
ç­–ç•¥ OnTick panic å¯èƒ½å½±éŸ¿å…¶ä»–ç­–ç•¥åŸ·è¡Œã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/strategy/engine.go`

```go
// æ–°å¢æ–¹æ³•
func (e *Engine) recoverFromPanic(strategyID string) {
    if r := recover(); r != nil {
        stack := debug.Stack()
        log.Printf("âŒ Strategy %s panicked: %v\n%s", strategyID, r, stack)
        
        // è‡ªå‹•æš«åœå‡ºéŒ¯ç­–ç•¥
        e.paused[strategyID] = true
        
        // ç™¼å¸ƒéŒ¯èª¤äº‹ä»¶
        e.bus.Publish(events.EventStrategyError, StrategyError{
            StrategyID: strategyID,
            Error:      fmt.Sprintf("%v", r),
            Stack:      string(stack),
            Timestamp:  time.Now(),
        })
    }
}
```

#### é©—æ”¶æ¨™æº–
- [ ] å–®ä¸€ç­–ç•¥ panic ä¸å½±éŸ¿å…¶ä»–ç­–ç•¥
- [ ] Panic ç­–ç•¥è‡ªå‹•æš«åœ
- [ ] éŒ¯èª¤äº‹ä»¶æ­£ç¢ºç™¼å¸ƒ

---

## Phase 2: æ€§èƒ½æ·±åº¦å„ªåŒ–

**æ™‚é–“**: ç¬¬ 3-4 é€±  
**ç›®æ¨™**: æå‡é—œéµè·¯å¾‘æ€§èƒ½

### 2.1 P0-B: è¨‚å–®ç•°æ­¥åŸ·è¡Œ

#### å•é¡Œæè¿°
ç•¶å‰ `Executor.Handle()` åŒæ­¥ç­‰å¾…äº¤æ˜“æ‰€å›æ‡‰ï¼Œé˜»å¡è¨‚å–®ä½‡åˆ—è™•ç†ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æ–°æª”æ¡ˆ**: `internal/order/async_executor.go`

```go
package order

import (
    "context"
    "log"
    "sync"
)

// AsyncExecutor wraps Executor for non-blocking execution.
type AsyncExecutor struct {
    executor   *Executor
    resultCh   chan ExecutionResult
    workerPool chan struct{}
    wg         sync.WaitGroup
}

type ExecutionResult struct {
    OrderID string
    Success bool
    Error   error
    Latency time.Duration
}

func NewAsyncExecutor(executor *Executor, workers int) *AsyncExecutor {
    if workers <= 0 {
        workers = 4
    }
    return &AsyncExecutor{
        executor:   executor,
        resultCh:   make(chan ExecutionResult, 100),
        workerPool: make(chan struct{}, workers),
    }
}

// ExecuteAsync submits order for async execution.
func (a *AsyncExecutor) ExecuteAsync(ctx context.Context, order Order) {
    a.wg.Add(1)
    a.workerPool <- struct{}{}
    
    go func() {
        defer a.wg.Done()
        defer func() { <-a.workerPool }()
        
        start := time.Now()
        err := a.executor.Handle(ctx, order)
        
        result := ExecutionResult{
            OrderID: order.ID,
            Success: err == nil,
            Error:   err,
            Latency: time.Since(start),
        }
        
        select {
        case a.resultCh <- result:
        default:
            log.Printf("âš ï¸ Result channel full, dropping result for %s", order.ID)
        }
    }()
}

// Results returns the result channel for monitoring.
func (a *AsyncExecutor) Results() <-chan ExecutionResult {
    return a.resultCh
}

// WaitAll waits for all pending executions.
func (a *AsyncExecutor) WaitAll() {
    a.wg.Wait()
}
```

#### æ•´åˆæ–¹å¼

**ä¿®æ”¹**: `main.go`

```go
// èˆŠä»£ç¢¼
exec := order.NewExecutor(database, bus, gateway, venue, cfg.BinanceTestnet)

// æ–°ä»£ç¢¼
exec := order.NewExecutor(database, bus, gateway, venue, cfg.BinanceTestnet)
asyncExec := order.NewAsyncExecutor(exec, 4)

// çµæœç›£æ§ goroutine
go func() {
    for result := range asyncExec.Results() {
        if !result.Success {
            log.Printf("âŒ Order %s failed: %v", result.OrderID, result.Error)
        }
        sysMetrics.OrderLatency.RecordDuration(result.Latency)
    }
}()

// ä¿®æ”¹ Drain
go orderQueue.Drain(ctx, func(o order.Order) {
    asyncExec.ExecuteAsync(ctx, o)
})
```

#### é©—æ”¶æ¨™æº–
- [ ] è¨‚å–®éé˜»å¡æäº¤
- [ ] æ”¯æ´æœ€å¤§ä¸¦ç™¼æ•¸é…ç½®
- [ ] åŸ·è¡Œçµæœå¯ç›£æ§
- [ ] å»¶é²æŒ‡æ¨™è‡ªå‹•è¨˜éŒ„

---

### 2.2 P1-B: æƒ°æ€§ Stats è¨ˆç®—

#### å•é¡Œæè¿°
ç•¶å‰ `LatencyHistogram.Stats()` æ¯æ¬¡èª¿ç”¨ O(n log n) æ’åºã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/monitor/metrics.go`

```go
type LatencyHistogram struct {
    mu         sync.Mutex
    samples    []float64
    maxSize    int
    
    // æƒ°æ€§è¨ˆç®—
    sorted     []float64
    dirty      bool
    cachedStats LatencyStats
}

func (h *LatencyHistogram) Record(latencyMs float64) {
    h.mu.Lock()
    defer h.mu.Unlock()
    
    if len(h.samples) >= h.maxSize {
        h.samples = h.samples[1:]
    }
    h.samples = append(h.samples, latencyMs)
    h.dirty = true  // æ¨™è¨˜éœ€é‡æ–°è¨ˆç®—
}

func (h *LatencyHistogram) Stats() LatencyStats {
    h.mu.Lock()
    defer h.mu.Unlock()
    
    if !h.dirty && h.cachedStats.Count > 0 {
        return h.cachedStats  // è¿”å›å¿«å–
    }
    
    n := len(h.samples)
    if n == 0 {
        return LatencyStats{}
    }
    
    // åƒ…åœ¨ dirty æ™‚é‡æ–°è¨ˆç®—
    h.sorted = make([]float64, n)
    copy(h.sorted, h.samples)
    sort.Float64s(h.sorted)
    
    var sum float64
    min, max := h.sorted[0], h.sorted[n-1]
    for _, v := range h.sorted {
        sum += v
    }
    
    h.cachedStats = LatencyStats{
        Min:   min,
        Max:   max,
        Avg:   sum / float64(n),
        P50:   h.sorted[n/2],
        P95:   h.sorted[int(float64(n)*0.95)],
        P99:   h.sorted[int(float64(n)*0.99)],
        Count: n,
    }
    h.dirty = false
    
    return h.cachedStats
}
```

#### é©—æ”¶æ¨™æº–
- [ ] é€£çºŒèª¿ç”¨ Stats() ç„¡é‡è¤‡æ’åº
- [ ] Record() å¾Œä¸‹æ¬¡ Stats() æ­£ç¢ºæ›´æ–°
- [ ] API éŸ¿æ‡‰å»¶é² < 1ms

---

### 2.3 P1-C: æ‰¹é‡ Drain Overflow

#### å•é¡Œæè¿°
ç•¶å‰ Drain æ¯æ¬¡è™•ç† overflow éƒ½ç²å–é–ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/order/queue.go`

```go
// æ–°å¢æ‰¹é‡å–å‡ºæ–¹æ³•
func (q *Queue) drainOverflowBatch() []Order {
    q.mu.Lock()
    if len(q.overflowBuf) == 0 {
        q.mu.Unlock()
        return nil
    }
    
    batch := q.overflowBuf
    q.overflowBuf = make([]Order, 0, cap(batch))
    q.mu.Unlock()
    
    return batch
}

// ä¿®æ”¹ Drain
func (q *Queue) Drain(ctx context.Context, handler func(Order)) {
    for {
        // æ‰¹é‡è™•ç† overflow
        if batch := q.drainOverflowBatch(); batch != nil {
            for _, o := range batch {
                atomic.AddUint64(&q.metrics.Dequeued, 1)
                handler(o)
            }
            continue
        }
        
        // è™•ç†ä¸» channel
        select {
        case <-ctx.Done():
            return
        case o, ok := <-q.ch:
            if !ok {
                return
            }
            atomic.AddUint64(&q.metrics.Dequeued, 1)
            handler(o)
        }
    }
}
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰¹é‡è™•ç†æ¸›å°‘é–ç²å–æ¬¡æ•¸
- [ ] ç„¡è¨‚å–®ä¸Ÿå¤±
- [ ] æ€§èƒ½æå‡å¯æ¸¬é‡

---

### 2.4 P1-D: BatchWriter æŒ‡æ¨™è¿½è¹¤

#### å•é¡Œæè¿°
`BatchWriterMetrics` å·²å®šç¾©ä½†æœªå¯¦éš›ä½¿ç”¨ã€‚

#### å¯¦æ–½æ–¹æ¡ˆ

**æª”æ¡ˆ**: `internal/persistence/batch_writer.go`

```go
type BatchWriter struct {
    // ... ç¾æœ‰æ¬„ä½ ...
    
    metrics BatchWriterMetrics
}

type BatchWriterMetrics struct {
    TotalWrites   uint64
    TotalBatches  uint64
    TotalErrors   uint64
    LastBatchSize int
    LastFlushTime time.Time
}

func (bw *BatchWriter) executeBatch(ops []WriteOp) error {
    if len(ops) == 0 {
        return nil
    }
    
    atomic.AddUint64(&bw.metrics.TotalWrites, uint64(len(ops)))
    atomic.AddUint64(&bw.metrics.TotalBatches, 1)
    bw.metrics.LastBatchSize = len(ops)
    bw.metrics.LastFlushTime = time.Now()
    
    tx, err := bw.db.Begin()
    if err != nil {
        atomic.AddUint64(&bw.metrics.TotalErrors, 1)
        return err
    }
    // ... å…¶é¤˜ä¸è®Š ...
}

// æ–°å¢æ–¹æ³•
func (bw *BatchWriter) GetMetrics() BatchWriterMetrics {
    return BatchWriterMetrics{
        TotalWrites:   atomic.LoadUint64(&bw.metrics.TotalWrites),
        TotalBatches:  atomic.LoadUint64(&bw.metrics.TotalBatches),
        TotalErrors:   atomic.LoadUint64(&bw.metrics.TotalErrors),
        LastBatchSize: bw.metrics.LastBatchSize,
        LastFlushTime: bw.metrics.LastFlushTime,
    }
}
```

---

## Phase 3: æ¶æ§‹å‡ç´šæº–å‚™

**æ™‚é–“**: ç¬¬ 5 é€±  
**ç›®æ¨™**: è©•ä¼°å’Œæº–å‚™è³‡æ–™åº«é·ç§»

### 3.1 P2-A: PostgreSQL é·ç§»è©•ä¼°

#### è©•ä¼°é …ç›®

| é …ç›® | èªªæ˜ | è² è²¬ |
|------|------|------|
| Schema å…¼å®¹æ€§ | SQLite â†’ PostgreSQL èªæ³•å·®ç•° | è‡ªå‹• |
| é€£ç·šæ± é…ç½® | æœ€å¤§é€£ç·šæ•¸ã€è¶…æ™‚è¨­å®š | é…ç½® |
| é·ç§»è…³æœ¬ | æ•¸æ“šé·ç§» SQL | æ‰‹å‹• |
| å›æ»¾è¨ˆåŠƒ | é·ç§»å¤±æ•—å¾©åŸ | æ‰‹å‹• |

#### æº–å‚™å·¥ä½œ

1. **æŠ½è±¡è³‡æ–™åº«ä»‹é¢**

**æ–°æª”æ¡ˆ**: `pkg/db/interface.go`

```go
package db

import (
    "context"
    "database/sql"
)

// Repository defines database operations interface.
type Repository interface {
    // Orders
    CreateOrder(ctx context.Context, order Order) error
    GetOrder(ctx context.Context, id string) (*Order, error)
    ListOrders(ctx context.Context, limit int) ([]Order, error)
    
    // Trades
    CreateTrade(ctx context.Context, trade Trade) error
    
    // Positions
    GetPosition(ctx context.Context, symbol string) (*Position, error)
    UpsertPosition(ctx context.Context, pos Position) error
    
    // Transactions
    Begin() (*sql.Tx, error)
}
```

2. **PostgreSQL é©…å‹•æº–å‚™**

```go
// pkg/db/postgres.go
package db

import (
    "database/sql"
    _ "github.com/lib/pq"
)

type PostgresDatabase struct {
    DB *sql.DB
}

func NewPostgres(connStr string) (*PostgresDatabase, error) {
    db, err := sql.Open("postgres", connStr)
    if err != nil {
        return nil, err
    }
    
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(5)
    db.SetConnMaxLifetime(5 * time.Minute)
    
    return &PostgresDatabase{DB: db}, nil
}
```

---

## Phase 4: è³‡æ–™åº«é·ç§»

**æ™‚é–“**: ç¬¬ 6 é€±  
**ç›®æ¨™**: å¯é¸åŸ·è¡Œ PostgreSQL é·ç§»

### 4.1 é·ç§»ç­–ç•¥

```
éšæ®µ A: é›™å¯«æ¨¡å¼ (å¯é¸)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite    â”‚â”€â”€â”€â–¶â”‚  PostgreSQL  â”‚
â”‚   (ä¸»åº«)    â”‚    â”‚   (å‚™åº«)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

éšæ®µ B: åˆ‡æ›ä¸»åº«
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite    â”‚    â”‚  PostgreSQL  â”‚
â”‚   (å‚™åº«)    â”‚â—€â”€â”€â”€â”‚   (ä¸»åº«)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

éšæ®µ C: ç§»é™¤ SQLite
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PostgreSQL  â”‚
                    â”‚   (å”¯ä¸€)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 é…ç½®è®Šæ›´

**ä¿®æ”¹**: `pkg/config/config.go`

```go
type Config struct {
    // ... ç¾æœ‰æ¬„ä½ ...
    
    // è³‡æ–™åº«é…ç½®
    DBType        string `env:"DB_TYPE" envDefault:"sqlite"`       // sqlite | postgres
    PostgresURL   string `env:"POSTGRES_URL"`                       // PostgreSQL é€£ç·šå­—ä¸²
    PostgresPool  int    `env:"POSTGRES_POOL" envDefault:"25"`     // é€£ç·šæ± å¤§å°
}
```

---

## å¯¦æ–½æ™‚é–“è¡¨

```mermaid
gantt
    title V2 æ”¹é€²è¨ˆç•«ç”˜ç‰¹åœ–
    dateFormat  YYYY-MM-DD
    section Phase 1
    P0-A Worker Pool       :a1, 2025-12-09, 3d
    P1-A Panic Recovery    :a2, after a1, 2d
    section Phase 2
    P0-B è¨‚å–®ç•°æ­¥åŸ·è¡Œ      :b1, 2025-12-16, 5d
    P1-B æƒ°æ€§ Stats        :b2, after b1, 2d
    P1-C æ‰¹é‡ Drain        :b3, after b1, 1d
    P1-D BatchWriter æŒ‡æ¨™  :b4, after b1, 1d
    section Phase 3
    P2-A PostgreSQL è©•ä¼°   :c1, 2025-12-30, 3d
    DB ä»‹é¢æŠ½è±¡            :c2, after c1, 2d
    section Phase 4
    PostgreSQL é©…å‹•        :d1, 2026-01-06, 3d
    é·ç§»æ¸¬è©¦               :d2, after d1, 2d
```

### è©³ç´°ä»»å‹™æ¸…å–®

| é€±æ¬¡ | ä»»å‹™ | ç‹€æ…‹ |
|------|------|------|
| Week 1 | P0-A: ç­–ç•¥ Worker Pool | ğŸ”² |
| Week 1 | P1-A: Panic Recovery | ğŸ”² |
| Week 2 | P0-B: è¨‚å–®ç•°æ­¥åŸ·è¡Œ | ğŸ”² |
| Week 2 | P1-B: æƒ°æ€§ Stats è¨ˆç®— | ğŸ”² |
| Week 3 | P1-C: æ‰¹é‡ Drain Overflow | ğŸ”² |
| Week 3 | P1-D: BatchWriter æŒ‡æ¨™è¿½è¹¤ | ğŸ”² |
| Week 4 | P2-A: PostgreSQL é·ç§»è©•ä¼° | ğŸ”² |
| Week 4 | è³‡æ–™åº«ä»‹é¢æŠ½è±¡ | ğŸ”² |
| Week 5 | PostgreSQL é©…å‹•å¯¦ä½œ | ğŸ”² |
| Week 5 | é·ç§»æ¸¬è©¦ | ğŸ”² |
| Week 6 | ç”Ÿç”¢é·ç§» (å¯é¸) | ğŸ”² |

---

## é¢¨éšªè©•ä¼°èˆ‡ç·©è§£

| é¢¨éšª | å¯èƒ½æ€§ | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|--------|------|----------|
| Worker Pool éå°å°è‡´å»¶é² | ä¸­ | ä¸­ | å¯é…ç½® pool size |
| ç•°æ­¥åŸ·è¡Œçµæœä¸Ÿå¤± | ä½ | é«˜ | çµæœ channel buffer + ç›£æ§ |
| PostgreSQL é·ç§»æ•¸æ“šä¸ä¸€è‡´ | ä½ | é«˜ | é›™å¯«é©—è­‰ + å›æ»¾è¨ˆåŠƒ |
| æƒ°æ€§è¨ˆç®—å¿«å–å¤±æ•ˆ | ä½ | ä½ | å®Œæ•´å–®å…ƒæ¸¬è©¦ |

---

## é©—æ”¶æ¨™æº–

### Phase 1 é©—æ”¶

- [ ] `go test -race` ç„¡ç«¶æ…‹æ¢ä»¶
- [ ] Goroutine æ•¸é‡ç©©å®š (< poolSize Ã— 3)
- [ ] ç­–ç•¥ panic ä¸å½±éŸ¿ç³»çµ±

### Phase 2 é©—æ”¶

- [ ] è¨‚å–®åŸ·è¡Œç•°æ­¥åŒ–
- [ ] `/api/metrics` å»¶é² < 1ms
- [ ] BatchWriter æŒ‡æ¨™å¯æŸ¥è©¢

### Phase 3-4 é©—æ”¶ (å¯é¸)

- [ ] PostgreSQL é©…å‹•å¯ç”¨
- [ ] é›™å¯«æ¸¬è©¦é€šé
- [ ] é·ç§»å›æ»¾å¯è¡Œ

---

## é™„éŒ„

### A. ç›¸é—œæ–‡ä»¶

- [æ€§èƒ½åˆ†æå ±å‘Š V2](../architecture/PERFORMANCE_ANALYSIS.md)
- [æ€§èƒ½æ”¹é€²è¨ˆç•« V1](./PERFORMANCE_IMPROVEMENT_PLAN_V1.md)
- [ç³»çµ±æ¶æ§‹](../architecture/SYSTEM_ARCHITECTURE.md)

### B. ç‰ˆæœ¬æ­·å²

| ç‰ˆæœ¬ | æ—¥æœŸ | è®Šæ›´ |
|------|------|------|
| 2.0 | 2025-12-08 | æ ¹æ“š V2 åˆ†æå»ºç«‹æ”¹é€²è¨ˆç•« |

---

*æœ¬è¨ˆç•«åŸºæ–¼ V2 æ€§èƒ½åˆ†æå ±å‘Šï¼Œé è¨ˆ 4-6 é€±å®Œæˆã€‚Phase 3-4 (è³‡æ–™åº«é·ç§») ç‚ºå¯é¸åŸ·è¡Œã€‚*
